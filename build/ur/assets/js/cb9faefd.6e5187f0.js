"use strict";(self.webpackChunkhackathon_book=self.webpackChunkhackathon_book||[]).push([[397],{5976(e,n,r){r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"module-3/ros2","title":"Chapter 6: ROS 2 Software Stack","description":"ROS 2 (Robot Operating System 2) is the de facto standard middleware for humanoid robotics. It provides:","source":"@site/docs/module-3/06-ros2.md","sourceDirName":"module-3","slug":"/module-3/ros2","permalink":"/hackathon-book/ur/docs/module-3/ros2","draft":false,"unlisted":false,"editUrl":"https://github.com/anthropics/hackathon-book/tree/main/docs/module-3/06-ros2.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 5: Hardware Compute & Real-Time OS","permalink":"/hackathon-book/ur/docs/module-3/compute"},"next":{"title":"Chapter 7: Safety, Redundancy & Integration","permalink":"/hackathon-book/ur/docs/module-3/safety"}}');var t=r(4848),i=r(8453);const s={},a="Chapter 6: ROS 2 Software Stack",l={},c=[{value:"Node Architecture for Humanoid Control",id:"node-architecture-for-humanoid-control",level:2},{value:"Real-Time Messaging with DDS",id:"real-time-messaging-with-dds",level:2},{value:"Sensor-Actuator Feedback Loops",id:"sensor-actuator-feedback-loops",level:2},{value:"Integration with Gazebo (Module 2 Connection)",id:"integration-with-gazebo-module-2-connection",level:2},{value:"References",id:"references",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"chapter-6-ros-2-software-stack",children:"Chapter 6: ROS 2 Software Stack"})}),"\n",(0,t.jsxs)(n.p,{children:["ROS 2 (Robot Operating System 2) is the ",(0,t.jsx)(n.strong,{children:"de facto standard middleware"})," for humanoid robotics. It provides:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Message passing"}),": Nodes communicate via pub-sub (publishers and subscribers)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Real-time support"}),": DDS (Data Distribution Service) middleware with QoS (Quality of Service) guarantees"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Tools"}),": Simulation integration (Gazebo), visualization (RViz), debugging"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"node-architecture-for-humanoid-control",children:"Node Architecture for Humanoid Control"}),"\n",(0,t.jsx)(n.p,{children:"A typical ROS 2 humanoid stack has these nodes:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-mermaid",children:'graph TB\r\n    subgraph HardwareInterface["Hardware Interface Layer"]\r\n        SensorDrivers["sensor_drivers<br/>(stereo_proc, imu_driver)<br/>100-1000 Hz"]\r\n        MotorDrivers["motor_drivers<br/>(hydraulic_control, servo_interface)<br/>200-1000 Hz"]\r\n    end\r\n\r\n    subgraph PerceptionLayer["Perception & Fusion"]\r\n        SensorFusion["sensor_fusion_node<br/>(EKF state estimation)<br/>200-500 Hz"]\r\n        VisionCNN["vision_perception<br/>(object_detect, grasp_planning)<br/>30 Hz"]\r\n    end\r\n\r\n    subgraph ControlLayer["Control Layer"]\r\n        Planner["motion_planner<br/>(trajectory generation)<br/>10-20 Hz"]\r\n        TrajectoryCtrl["trajectory_controller<br/>(joint servoing, balance)<br/>200-1000 Hz"]\r\n    end\r\n\r\n    subgraph MonitoringLayer["Monitoring & Safety"]\r\n        Watchdog["watchdog_monitor<br/>(deadline detection)<br/>1000 Hz"]\r\n        SafetyMonitor["safety_monitor<br/>(E-stop, fail-safe)<br/>100 Hz"]\r\n    end\r\n\r\n    SensorDrivers --\x3e|Raw: Vision, IMU, Encoders<br/>DDS Topics @ High Freq| SensorFusion\r\n    SensorDrivers --\x3e|Image Stream<br/>30 Hz| VisionCNN\r\n    SensorFusion --\x3e|Estimated State<br/>(position, velocity, orientation)| Planner\r\n    Planner --\x3e|Desired Trajectory| TrajectoryCtrl\r\n    TrajectoryCtrl --\x3e|Joint Torques/Positions| MotorDrivers\r\n    MotorDrivers --\x3e|Actuator Commands| SensorDrivers\r\n    TrajectoryCtrl --\x3e|Heartbeat| Watchdog\r\n    SensorFusion --\x3e|Status| SafetyMonitor\r\n    Watchdog --\x3e|Timeout?| SafetyMonitor\r\n    VisionCNN --\x3e|Detected Objects| Planner\r\n\r\n    style HardwareInterface fill:#c8e6c9\r\n    style PerceptionLayer fill:#bbdefb\r\n    style ControlLayer fill:#ffe0b2\r\n    style MonitoringLayer fill:#ffccbc\n'})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Diagram 3: ROS 2 Node Architecture"})," \u2014 Layered node graph showing data dependencies and communication frequencies. Nodes with tight deadlines (control loop) run at high frequency with real-time QoS settings; perception nodes run at lower frequency with best-effort QoS. Feedback closes the loop through the Hardware Interface Layer. [SOURCE: ROS 2 real-time patterns - FR-008 SC-003]"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Sensor Drivers"})," (stereo_image_proc, imu_filter_madgwick):"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Read raw sensor data (camera frames, IMU samples, joint encoders)"}),"\n",(0,t.jsx)(n.li,{children:"Publish on high-frequency topics (100\u20131000 Hz)"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Sensor Fusion Node"})," (state_estimator):"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Subscribes to sensor topics"}),"\n",(0,t.jsx)(n.li,{children:"Runs EKF to estimate robot state (position, velocity, orientation)"}),"\n",(0,t.jsx)(n.li,{children:"Publishes fused state at control loop frequency"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Motion Planner"})," (move_base, traj_planner):"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Runs at lower frequency (10\u201320 Hz) to decide high-level goals"}),"\n",(0,t.jsx)(n.li,{children:"Publishes desired trajectory or setpoints"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Trajectory Controller"})," (joint_trajectory_controller, model_predictive_controller):"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Runs at high frequency (200\u20131000 Hz)"}),"\n",(0,t.jsx)(n.li,{children:"Tracks desired trajectory, computes joint torques"}),"\n",(0,t.jsx)(n.li,{children:"Publishes commands to actuators"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Motor Drivers"})," (hardware interfaces):"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Lowest level: commands to hydraulic valves or motor controllers"}),"\n",(0,t.jsx)(n.li,{children:"Reads back actual joint positions and torques"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"real-time-messaging-with-dds",children:"Real-Time Messaging with DDS"}),"\n",(0,t.jsxs)(n.p,{children:["Standard ROS messaging (based on TCP) has unpredictable latency. ",(0,t.jsx)(n.strong,{children:"DDS (Data Distribution Service)"})," enables ",(0,t.jsx)(n.strong,{children:"real-time publish-subscribe"}),":"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"QoS (Quality of Service) settings"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Reliability"}),": Guaranteed delivery vs. best-effort"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"History"}),": Keep latest message vs. keep all messages"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Deadline"}),": Message must arrive within N milliseconds"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Durability"}),": Topic survives node restarts"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"For the control loop (hard real-time), we set:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Reliability: Reliable (guaranteed delivery)"}),"\n",(0,t.jsx)(n.li,{children:"Deadline: less than 10 ms (stricter than publish frequency for margin)"}),"\n",(0,t.jsx)(n.li,{children:"History: Keep latest only (no buffering to maintain freshness)"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"For perception (soft real-time), we might use:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Reliability: Best-effort (skip stale images)"}),"\n",(0,t.jsx)(n.li,{children:"Deadline: 100 ms (comfortable margin for 30 Hz perception)"}),"\n",(0,t.jsx)(n.li,{children:"History: Keep latest only"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"(ROS 2 Documentation, 2024)"}),"\n",(0,t.jsx)(n.h2,{id:"sensor-actuator-feedback-loops",children:"Sensor-Actuator Feedback Loops"}),"\n",(0,t.jsxs)(n.p,{children:["A key aspect of real-time control is ",(0,t.jsx)(n.strong,{children:"closing the loop fast"}),":"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Walking example"}),":"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"IMU detects robot is tipping forward (accel = 0.5 g forward)"}),"\n",(0,t.jsx)(n.li,{children:"Sensor fusion updates state: lean angle = 8\xb0, forward velocity = 0.3 m/s"}),"\n",(0,t.jsx)(n.li,{children:"Control loop reads new state"}),"\n",(0,t.jsx)(n.li,{children:'Controller computes: "Increase hip torque by 50 Nm to recover"'}),"\n",(0,t.jsx)(n.li,{children:"Motor driver commands hip motors"}),"\n",(0,t.jsx)(n.li,{children:"Hydraulic pressure increases, hip joint accelerates"}),"\n",(0,t.jsx)(n.li,{children:"Joint encoder shows hip angle changing"}),"\n",(0,t.jsx)(n.li,{children:"Next control cycle (10 ms later): IMU detects tipping has slowed, new state is lean = 7\xb0, controller reduces torque"}),"\n",(0,t.jsx)(n.li,{children:"Repeat: tight feedback loop stabilizes walking"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["This entire sequence must complete in ",(0,t.jsx)(n.strong,{children:"less than 10 ms"})," (one control cycle) for smooth balance. (Wang et al., 2025)"]}),"\n",(0,t.jsx)(n.h2,{id:"integration-with-gazebo-module-2-connection",children:"Integration with Gazebo (Module 2 Connection)"}),"\n",(0,t.jsxs)(n.p,{children:["ROS 2 communicates with Gazebo via ",(0,t.jsx)(n.code,{children:"gazebo_ros_control"}),": the same node architecture runs in both simulation (Gazebo) and reality (real hardware). This enables:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Testing control algorithms in simulation"})," before deploying to real robots"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Faster development"}),": iterate 100 times in Gazebo, then validate on real hardware"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Safe experimentation"}),": crash the simulated robot freely"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Module 2 taught you how to build Gazebo models. Module 3 teaches the hardware constraints those models must respect. Module 4 will teach control algorithms that run in both simulation (via ROS 2 Gazebo bridge) and reality."}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,t.jsxs)(n.p,{children:["Barbalace, A., Luchetta, A., Schmidt, G., Stitt, L., Phelps, P., & Xenofon, D. (2020). Real-time design based on PREEMPT_RT and timing analysis of collaborative robot control system. In ",(0,t.jsx)(n.em,{children:"Intelligent Robotics and Applications: 14th International Conference, ICIRA 2021"})," (pp. 607\u2013619). Springer. ",(0,t.jsx)(n.a,{href:"https://doi.org/10.1007/978-3-030-89098-8_56",children:"https://doi.org/10.1007/978-3-030-89098-8_56"})]}),"\n",(0,t.jsxs)(n.p,{children:["Qiu, Y., Zhang, Y., Huang, Z., Liu, H., & Hu, Y. (2024). Deep Reinforcement Learning for Sim-to-Real Transfer in a Humanoid Robot Barista. ",(0,t.jsx)(n.em,{children:"2024 IEEE-RAS 23rd International Conference on Humanoid Robots (Humanoids)"}),", 1\u20138. IEEE. ",(0,t.jsx)(n.a,{href:"https://ieeexplore.ieee.org/document/10907454/",children:"https://ieeexplore.ieee.org/document/10907454/"})]}),"\n",(0,t.jsxs)(n.p,{children:["ROS 2 Documentation. (2024). Real-Time Middleware and DDS Configuration. Retrieved from ",(0,t.jsx)(n.a,{href:"https://docs.ros.org/",children:"https://docs.ros.org/"})]}),"\n",(0,t.jsxs)(n.p,{children:["Sheridan, T. B., & Parasuraman, R. (2022). Robotic Vision for Human-Robot Interaction and Collaboration: A Survey and Systematic Review. ",(0,t.jsx)(n.em,{children:"ACM Transactions on Human-Robot Interaction"}),", Vol. 12, No. 1, Article 4, 1\u201366. ACM. ",(0,t.jsx)(n.a,{href:"https://doi.org/10.1145/3570731",children:"https://doi.org/10.1145/3570731"})]}),"\n",(0,t.jsxs)(n.p,{children:["Wang, X., Guo, W., Zhang, T., Lu, Z., & Zhao, M. (2025). Robust Dynamic Walking for Humanoid Robots via Computationally Efficient Footstep Planner and Whole-Body Control. ",(0,t.jsx)(n.em,{children:"Journal of Intelligent & Robotic Systems"}),", Vol. 111, Article 49. Springer. ",(0,t.jsx)(n.a,{href:"https://doi.org/10.1007/s10846-025-02249-w",children:"https://doi.org/10.1007/s10846-025-02249-w"})]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453(e,n,r){r.d(n,{R:()=>s,x:()=>a});var o=r(6540);const t={},i=o.createContext(t);function s(e){const n=o.useContext(i);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),o.createElement(i.Provider,{value:n},e.children)}}}]);